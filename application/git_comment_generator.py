#!/usr/bin/env python3
import argparse
import random
import sys
import subprocess

import torch
from colorama import init, Fore, Style
from transformers import TextStreamer

from eval_model import setup_seed, init_model

init(autoreset=True)  # åˆå§‹åŒ– colorama ä»¥æ”¯æŒ Windows å’Œ ANSI é¢œè‰²


def print_help(msg=None):
    """æ‰“å°å¸®åŠ©ä¿¡æ¯ï¼Œå¸¦é¢œè‰²"""
    if msg:
        print(f"{Fore.RED}{msg}{Style.RESET_ALL}")
    print(f"{Fore.YELLOW}Usage:{Style.RESET_ALL}")
    print(f"  python {sys.argv[0]} 'git diff --cached'")


def main():
    parser = argparse.ArgumentParser(description="Chat with MiniMind")
    parser.add_argument('--git_command', default="git diff master", type=str)
    parser.add_argument('--lora_name', default='None', type=str)
    parser.add_argument('--out_dir', default='out', type=str)
    parser.add_argument('--temperature', default=0.85, type=float)
    parser.add_argument('--top_p', default=0.85, type=float)
    parser.add_argument('--device',
                        default='cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu',
                        type=str)
    # æ­¤å¤„max_seq_lenï¼ˆæœ€å¤§è¾“å‡ºé•¿åº¦ï¼‰å¹¶ä¸æ„å‘³æ¨¡å‹å…·æœ‰å¯¹åº”çš„é•¿æ–‡æœ¬çš„æ€§èƒ½ï¼Œä»…é˜²æ­¢QAå‡ºç°è¢«æˆªæ–­çš„é—®é¢˜
    # MiniMind2-moe (145M)ï¼š(hidden_size=640, num_hidden_layers=8, use_moe=True)
    # MiniMind2-Small (26M)ï¼š(hidden_size=512, num_hidden_layers=8)
    # MiniMind2 (104M)ï¼š(hidden_size=768, num_hidden_layers=16)
    parser.add_argument('--hidden_size', default=512, type=int)
    parser.add_argument('--num_hidden_layers', default=8, type=int)
    parser.add_argument('--max_seq_len', default=8192, type=int)
    parser.add_argument('--use_moe', default=False, type=bool)
    # æºå¸¦å†å²å¯¹è¯ä¸Šä¸‹æ–‡æ¡æ•°
    # history_cntéœ€è¦è®¾ä¸ºå¶æ•°ï¼Œå³ã€ç”¨æˆ·é—®é¢˜, æ¨¡å‹å›ç­”ã€‘ä¸º1ç»„ï¼›è®¾ç½®ä¸º0æ—¶ï¼Œå³å½“å‰queryä¸æºå¸¦å†å²ä¸Šæ–‡
    # æ¨¡å‹æœªç»è¿‡å¤–æ¨å¾®è°ƒæ—¶ï¼Œåœ¨æ›´é•¿çš„ä¸Šä¸‹æ–‡çš„chat_templateæ—¶éš¾å…å‡ºç°æ€§èƒ½çš„æ˜æ˜¾é€€åŒ–ï¼Œå› æ­¤éœ€è¦æ³¨æ„æ­¤å¤„è®¾ç½®
    parser.add_argument('--history_cnt', default=0, type=int)
    parser.add_argument('--load', default=0, type=int, help="0: åŸç”Ÿtorchæƒé‡ï¼Œ1: transformersåŠ è½½")
    parser.add_argument('--model_mode', default=1, type=int,
                        help="0: é¢„è®­ç»ƒæ¨¡å‹ï¼Œ1: SFT-Chatæ¨¡å‹ï¼Œ2: RLHF-Chatæ¨¡å‹ï¼Œ3: Reasonæ¨¡å‹ï¼Œ4: RLAIF-Chatæ¨¡å‹")
    args = parser.parse_args()
    # print('[DEBUG] args: ', args)
    # print(f"[DEBUG] sys.argv: {sys.argv}")
    print("[DEBUG] ç›®å‰ä½¿ç”¨çš„æ¨ç†è®¾å¤‡ä¸º", args.device)


    # è¯»å–å‘½ä»¤è¡Œå‚æ•°
    if not args.git_command:
        # æŠ›å‡ºå¼‚å¸¸
        print_help("è¯·è¾“å…¥git diffå‘½ä»¤")
        return 1

    cmd_arg = args.git_command
    print("[DEBUG] cmd_arg: ", cmd_arg)

    # åˆå§‹åŒ–æ¨¡å‹å’Œtokenizer
    model, tokenizer = init_model(args)
    setup_seed(random.randint(0, 2048))

    # è·å¾—æµå¼è¾“å‡ºå™¨
    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)

    # è·å–è¾“å…¥å†…å®¹
    user_prompt = input("ğŸ‘¶: ")
    input_data = ""
    if cmd_arg:
        # æ‰§è¡Œå‘½ä»¤è·å– diff å†…å®¹
        result = subprocess.run(cmd_arg, shell=True, capture_output=True, text=True)
        input_data = result.stdout
        # print("[DEBUG] input_data: ", input_data)
    else:
        print_help("No git diff or text was passed to this function.")
        return 1

    # æ„é€  prompt
    # æç¤ºè¯å·¥ç¨‹
    prompt =     f"""ä½ æ˜¯ä¸€ä¸ªgitæäº¤ä¿¡æ¯ç”Ÿæˆæ¨¡å‹ï¼Œä½ éœ€è¦æ ¹æ®æˆ‘æä¾›çš„gitå·®å¼‚å†…å®¹ç”Ÿæˆæäº¤ä¿¡æ¯ï¼Œå¯ä»¥å‚è€ƒç”¨æˆ·çš„æç¤º\"{user_prompt}\"ï¼š```{input_data}```"""
    print('[DEBUG] prompt: ', prompt)

    # è°ƒç”¨minimindæœ¬åœ°æ¨¡å‹
    try:
        # æ„é€ messages
        messages = [{"role": "user", "content": prompt}]

        # å°†ç”¨æˆ·ä¸åŠ©æ‰‹ä¹‹é—´çš„å¤šè½®å¯¹è¯è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼(ä¸€ç§ç‰¹æ®Šçš„æ ¼å¼ï¼Œç±»ä¼¼äºjson)
        new_prompt = tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        ) if args.model_mode != 0 else (tokenizer.bos_token + prompt)

        # # å°†æ–‡æœ¬è¾“å…¥ new_prompt è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„å¼ é‡æ ¼å¼ï¼ˆtoken IDs å’Œ attention maskï¼‰
        # inputs = tokenizer(
        #     new_prompt,
        #     return_tensors="pt",
        #     truncation=True
        # ).to(args.device)

        try:
            # å°†æ–‡æœ¬è¾“å…¥ new_prompt è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„å¼ é‡æ ¼å¼ï¼ˆtoken IDs å’Œ attention maskï¼‰
            inputs = tokenizer(
                new_prompt,
                return_tensors="pt",
                truncation=True
            ).to(args.device)
        except Exception as e:
            if 'MPS' in str(e):
                print("æ£€æµ‹åˆ°MPSé”™è¯¯ï¼Œè‡ªåŠ¨å›é€€åˆ°CPUæ¨¡å¼")
                # å°†æ–‡æœ¬è¾“å…¥ new_prompt è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥å¤„ç†çš„å¼ é‡æ ¼å¼ï¼ˆtoken IDs å’Œ attention maskï¼‰
                inputs = tokenizer(
                    new_prompt,
                    return_tensors="pt",
                    truncation=True
                ).to("cpu")
            else:
                raise e

        print('ğŸ¤–ï¸: ', end='')
        # å¾—åˆ°æ¨¡å‹è¾“å‡ºçš„tokenIds
        generated_ids = model.generate(
            inputs["input_ids"],
            max_new_tokens=args.max_seq_len,
            num_return_sequences=1,
            do_sample=True,
            attention_mask=inputs["attention_mask"],
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
            streamer=streamer,
            top_p=args.top_p,
            temperature=args.temperature
        )
        # print('[DEBUG] generated_ids: ', generated_ids)

        # æ ¹æ®æ¨¡å‹ç”Ÿæˆçš„tokenIdsï¼Œç”Ÿæˆå¯¹åº”çš„response(æ–‡æœ¬)
        response = tokenizer.decode(generated_ids[0][inputs["input_ids"].shape[1]:], skip_special_tokens=True)
        messages.append({"role": "assistant", "content": response})
        print('\n\n')
        # todo: é‡‡ç”¨git commentæ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼ˆæ•°æ®æ¥æºï¼šå®éªŒå®¤å†…éƒ¨å·²æœ‰çš„git commentï¼Œé€šè¿‡è„šæœ¬ç»„è£…æˆæ•°æ®é›†ï¼‰
        # todo: å¯ä»¥æ”¹è¿›çš„ç‚¹ï¼šå°†ä¸Šä¸€ç‰ˆå®Œæ•´ä»£ç è¿›è¡ŒRAGåå¬å›ç›¸å…³ä»£ç ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œæå‡æ¨¡å‹çš„ç†è§£èƒ½åŠ›
        return None
    except Exception as e:
        print(e)
        return None


if __name__ == "__main__":
    main()